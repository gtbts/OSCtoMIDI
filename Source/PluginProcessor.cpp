/*
 ==============================================================================
 
 This file was auto-generated by the Introjucer!
 
 It contains the basic framework code for a JUCE plugin processor.
 
 ==============================================================================
 */

#include "PluginProcessor.h"
#include "PluginEditor.h"
#include "QuanMap.h"


//==============================================================================
OsctoMidiAudioProcessor::OsctoMidiAudioProcessor()
{
    addParameter (paramCV1Mute = new AudioParameterBool ("muteCV1",  "MuteCV1", false));
    addParameter (paramCV2Mute = new AudioParameterBool ("muteCV2",  "MuteCV2", false));
    addParameter (paramCV3Mute = new AudioParameterBool ("muteCV3",  "MuteCV3", false));
    addParameter (paramCV4Mute = new AudioParameterBool ("muteCV4",  "MuteCV4", false));
    addParameter (paramScale = new AudioParameterInt ("scale",  "Scale", 1, 8, 1));
    addParameter (paramBit = new AudioParameterInt ("bit",  "Bit", 1, 4, 2));
    
    setOSCConnection(9000);
    receiver.addListener (this);
}

OsctoMidiAudioProcessor::~OsctoMidiAudioProcessor()
{
}

//==============================================================================
const String OsctoMidiAudioProcessor::getName() const
{
    return JucePlugin_Name;
}

bool OsctoMidiAudioProcessor::acceptsMidi() const
{
#if JucePlugin_WantsMidiInput
    return true;
#else
    return false;
#endif
}

bool OsctoMidiAudioProcessor::producesMidi() const
{
#if JucePlugin_ProducesMidiOutput
    return true;
#else
    return false;
#endif
}

bool OsctoMidiAudioProcessor::silenceInProducesSilenceOut() const
{
    return false;
}

double OsctoMidiAudioProcessor::getTailLengthSeconds() const
{
    return 0.0;
}

int OsctoMidiAudioProcessor::getNumPrograms()
{
    return 1;   // NB: some hosts don't cope very well if you tell them there are 0 programs,
    // so this should be at least 1, even if you're not really implementing programs.
}

int OsctoMidiAudioProcessor::getCurrentProgram()
{
    return 0;
}

void OsctoMidiAudioProcessor::setCurrentProgram (int index)
{
}

const String OsctoMidiAudioProcessor::getProgramName (int index)
{
    return String();
}

void OsctoMidiAudioProcessor::changeProgramName (int index, const String& newName)
{
}

//==============================================================================
void OsctoMidiAudioProcessor::prepareToPlay (double sampleRate, int samplesPerBlock)
{
    // Use this method as the place to do any pre-playback
    // initialisation that you need..
}

void OsctoMidiAudioProcessor::releaseResources()
{
    // When playback stops, you can use this as an opportunity to free up any
    // spare memory, etc.
}

void OsctoMidiAudioProcessor::processBlock (AudioSampleBuffer& buffer, MidiBuffer& midiMessages)
{
    // In case we have more outputs than inputs, this code clears any output
    // channels that didn't contain input data, (because these aren't
    // guaranteed to be empty - they may contain garbage).
    // I've added this to avoid people getting screaming feedback
    // when they first compile the plugin, but obviously you don't need to
    // this code if your algorithm already fills all the output channels.
    
    MidiBuffer processedMidi;
    MidiMessage m;
    int time;
    
    for (MidiBuffer::Iterator i (midiMessages); i.getNextEvent (m, time);)
    {
        int note = m.getNoteNumber();
        
        if (m.isNoteOn())
        {
            if (note == 36) { cvMute[CV1] = true; } //C2
            if (note == 38) { cvMute[CV2] = true; } //D2
            if (note == 40) { cvMute[CV3] = true; } //E2
            if (note == 41) { cvMute[CV4] = true; } //F2
            
            
        } else if (m.isNoteOff()) {
            
            if (note == 36) { cvMute[CV1] = false; }
            if (note == 38) { cvMute[CV2] = false; }
            if (note == 40) { cvMute[CV3] = false; }
            if (note == 41) { cvMute[CV4] = false; }
            
        } else if (m.isControllerOfType(1)) { // Modulation Wheel
            
        }
        
        paramCV1Mute->setValueNotifyingHost(static_cast<float>(cvMute[CV1]));
        paramCV2Mute->setValueNotifyingHost(static_cast<float>(cvMute[CV2]));
        paramCV3Mute->setValueNotifyingHost(static_cast<float>(cvMute[CV3]));
        paramCV4Mute->setValueNotifyingHost(static_cast<float>(cvMute[CV4]));
    }
    
    uint16_t oscCV;
    uint8_t note;
    static uint8_t _note[4];
    bool mute;
    
    for (int ch = 0; ch < 4; ++ch)
    {
        switch (ch)
        {
            case CV1:
                cvMute[CV1] ? mute = true : oscCV = cvValue[CV1]; mute = false;
                break;
            case CV2:
                cvMute[CV2] ? mute = true : oscCV = cvValue[CV2]; mute = false;
                break;
            case CV3:
                cvMute[CV3] ? mute = true : oscCV = cvValue[CV3]; mute = false;
                break;
            case CV4:
                cvMute[CV4] ? mute = true : oscCV = cvValue[CV4]; mute = false;
                break;
                
            default:
                break;
        }
        
        switch (currentScale)
        {
            case Chromatic:
                note = Map(oscCV, 0, currentResolution, 0, 127);
                break;
            case Major:
                note = calibMap2[Map(oscCV, 0, currentResolution, 0, QUAN_RES2 - 1)];
                break;
            case M7:
                note = calibMap3[Map(oscCV, 0, currentResolution, 0, QUAN_RES3 - 1)];
                break;
            case Min7:
                note = calibMap4[Map(oscCV, 0, currentResolution, 0, QUAN_RES4 - 1)];
                break;
            case Dorian :
                note = calibMap5[Map(oscCV, 0, currentResolution, 0, QUAN_RES5 - 1)];
                break;
            case Minor:
                note = calibMap6[Map(oscCV, 0, currentResolution, 0, QUAN_RES6 - 1)];
                break;
            case Fifth:
                note = calibMap7[Map(oscCV, 0, currentResolution, 0, QUAN_RES7 - 1)];
                break;
            case Whole :
                note = calibMap8[Map(oscCV, 0, currentResolution, 0, QUAN_RES8 - 1)];
                break;
                
            default:
                break;
        }
        
        if (!mute)
        {
            if (_note[ch] != note)
            {
                processedMidi.addEvent (MidiMessage::noteOff  (1, _note[ch], (uint8_t) 0), time);
                processedMidi.addEvent (MidiMessage::noteOn  (1, note, (uint8_t) 90), time);
                
                _note[ch] = note;
            }
        }
    }
    
    midiMessages.swapWith (processedMidi);
    
    buffer.clear();
    
    for (int channel = 0; channel < getNumInputChannels(); ++channel)
    {
        float* channelData = 0;
    }
}

//==============================================================================
bool OsctoMidiAudioProcessor::hasEditor() const
{
    return true; // (change this to false if you choose to not supply an editor)
}

AudioProcessorEditor* OsctoMidiAudioProcessor::createEditor()
{
    return new OsctoMidiAudioProcessorEditor (*this);
}

//==============================================================================
void OsctoMidiAudioProcessor::getStateInformation (MemoryBlock& destData)
{
    // You should use this method to store your parameters in the memory block.
    // You could do that either as raw data, or use the XML or ValueTree classes
    // as intermediaries to make it easy to save and load complex data.
    
    MemoryOutputStream stream (destData, true);
    
    stream.writeBool (*paramCV1Mute);
    stream.writeBool (*paramCV2Mute);
    stream.writeBool (*paramCV3Mute);
    stream.writeBool (*paramCV4Mute);
    stream.writeInt (*paramScale);
    stream.writeInt(*paramBit);
}

void OsctoMidiAudioProcessor::setStateInformation (const void* data, int sizeInBytes)
{
    // You should use this method to restore your parameters from this memory block,
    // whose contents will have been created by the getStateInformation() call.
    
    MemoryInputStream stream (data, static_cast<size_t> (sizeInBytes), false);
    
    paramCV1Mute->setValueNotifyingHost (stream.readBool());
    paramCV2Mute->setValueNotifyingHost (stream.readBool());
    paramCV3Mute->setValueNotifyingHost (stream.readBool());
    paramCV4Mute->setValueNotifyingHost (stream.readBool());
    paramScale->setValueNotifyingHost (stream.readInt());
    paramBit->setValueNotifyingHost(stream.readInt());
}

//==============================================================================
void OsctoMidiAudioProcessor::setOSCConnection (uint16_t port)
{
    receiver.disconnect();
    
    if (!receiver.connect(port))
    {
        showConnectionErrorMessage("Error: could not connect to UDP port.");
    }
}

void OsctoMidiAudioProcessor::showConnectionErrorMessage (const String& messageText)
{
    AlertWindow::showMessageBoxAsync (
                                      AlertWindow::WarningIcon,
                                      "Connection error",
                                      messageText,
                                      "OK");
}

void OsctoMidiAudioProcessor::oscMessageReceived (const OSCMessage& message)
{
    int32_t value;
    
    if (message[0].isInt32())
    {
        value = message[0].getInt32();
        
    } else if (message[0].isFloat32()) {
        
        value = static_cast<int>(message[0].getFloat32());
    }
    
    if (OSCAddressPattern("/acv1") == message.getAddressPattern() && value <= currentResolution)
    {
        cvValue[CV1] = value;
        
    } else if (OSCAddressPattern("/acv2") == message.getAddressPattern() && value <= currentResolution) {
        
        cvValue[CV2] = value;
        
    } else if (OSCAddressPattern("/acv3") == message.getAddressPattern() && value <= currentResolution) {
        
        cvValue[CV3] = value;
        
    } else if (OSCAddressPattern("/acv4") == message.getAddressPattern() && value <= currentResolution) {
        
        cvValue[CV4] = value;
    }
}

void OsctoMidiAudioProcessor::oscBundleReceived (const OSCBundle& bundle)
{
    for (int i = 0; i < bundle.size(); ++i)
    {
        OSCBundle::Element element = bundle[i];
        OSCMessage message = element.getMessage();
        
        int32_t value;
        
        if (message[0].isInt32())
        {
            value = message[0].getInt32();
            
        } else if (message[0].isFloat32()) {
            
            value = static_cast<int>(message[0].getFloat32());
        }
        
        if (OSCAddressPattern("/acv1") == message.getAddressPattern() && value <= currentResolution)
        {
            cvValue[CV1] = value;
            
        } else if (OSCAddressPattern("/acv2") == message.getAddressPattern() && value <= currentResolution) {
            
            cvValue[CV2] = value;
            
        } else if (OSCAddressPattern("/acv3") == message.getAddressPattern() && value <= currentResolution) {
            
            cvValue[CV3] = value;
            
        } else if (OSCAddressPattern("/acv4") == message.getAddressPattern() && value <= currentResolution) {
            
            cvValue[CV4] = value;
        }
    }
}

//==============================================================================
// This creates new instances of the plugin..
AudioProcessor* JUCE_CALLTYPE createPluginFilter()
{
    return new OsctoMidiAudioProcessor();
}
